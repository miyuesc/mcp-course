# MCP 的架构组件

在上一节中，我们讨论了 MCP 的关键概念和术语。现在，让我们深入了解构成 MCP 生态系统的架构组件。

## 主机、客户端和服务器

模型上下文协议 (MCP) 建立在客户端-服务器架构之上，该架构实现了 AI 模型和外部系统之间的结构化通信。

![MCP 架构](https://huggingface.co/datasets/mcp-course/images/resolve/main/unit1/4.png)

MCP 架构由三个主要组件组成，每个组件都有明确定义的角色和职责：主机、客户端和服务器。我们在上一节中提到了这些，但让我们深入了解每个组件及其职责。

### 主机

**主机**是面向用户的 AI 应用程序，最终用户直接与之交互。

示例包括：
- AI 聊天应用程序，如 OpenAI ChatGPT 或 Anthropic 的 Claude Desktop
- AI 增强的 IDE，如 Cursor，或与 Continue.dev 等工具的集成
- 在 LangChain 或 smolagents 等库中构建的自定义 AI 代理和应用程序

主机的职责包括：
- 管理用户交互和权限
- 通过 MCP 客户端启动与 MCP 服务器的连接
- 协调用户请求、LLM 处理和外部工具之间的整体流程
- 以连贯的格式将结果呈现给用户

在大多数情况下，用户将根据他们的需求和偏好选择主机应用程序。例如，开发者可能会选择 Cursor 因其强大的代码编辑能力，而领域专家可能使用在 smolagents 中构建的自定义应用程序。

### 客户端

**客户端**是主机应用程序内管理与特定 MCP 服务器通信的组件。关键特征包括：

- 每个客户端与单个服务器保持 1:1 连接
- 处理 MCP 通信的协议级细节
- 充当主机逻辑和外部服务器之间的中介

### 服务器

**服务器**是通过 MCP 协议向 AI 模型公开能力的外部程序或服务。服务器：

- 提供对特定外部工具、数据源或服务的访问
- 充当现有功能的轻量级包装器
- 可以在本地运行（与主机在同一台机器上）或远程运行（通过网络）
- 以客户端可以发现和使用的标准化格式公开其能力

## 通信流程

让我们检查这些组件在典型 MCP 工作流程中如何交互：

<Tip>

在下一节中，我们将通过实际示例深入了解使这些组件能够工作的通信协议。

</Tip>

1. **用户交互**：用户与**主机**应用程序交互，表达意图或查询。

2. **主机处理**：**主机**处理用户的输入，可能使用 LLM 来理解请求并确定可能需要哪些外部能力。

3. **客户端连接**：**主机**指示其**客户端**组件连接到适当的服务器。

4. **能力发现**：**客户端**查询**服务器**以发现它提供的能力（工具、资源、提示）。

5. **能力调用**：基于用户的需求或 LLM 的确定，主机指示**客户端**从**服务器**调用特定能力。

6. **服务器执行**：**服务器**执行请求的功能并将结果返回给**客户端**。

7. **结果集成**：**客户端**将这些结果转发回**主机**，主机将它们纳入 LLM 的上下文或直接呈现给用户。

这种架构的一个关键优势是其模块化。单个**主机**可以通过不同的**客户端**同时连接到多个**服务器**。新的**服务器**可以添加到生态系统中，而无需更改现有的**主机**。能力可以轻松地在不同的**服务器**之间组合。

<Tip>

正如我们在上一节中讨论的，这种模块化将传统的 M×N 集成问题（M 个 AI 应用程序连接到 N 个工具/服务）转换为更易管理的 M+N 问题，其中每个主机和服务器只需实现一次 MCP 标准。

</Tip>

架构可能看起来简单，但其力量在于通信协议的标准化和组件之间职责的清晰分离。这种设计允许一个有凝聚力的生态系统，其中 AI 模型可以与不断增长的外部工具和数据源阵列无缝连接。

## 结论

这些交互模式由几个关键原则指导，这些原则塑造了 MCP 的设计和演进。该协议通过为 AI 连接提供通用协议来强调**标准化**，同时通过保持核心协议简单但启用高级功能来维持**简单性**。通过要求对敏感操作进行明确的用户批准来优先考虑**安全性**，可发现性使能力的动态发现成为可能。该协议在设计时考虑了**可扩展性**，通过版本控制和能力协商支持演进，并确保跨不同实现和环境的**互操作性**。

在下一节中，我们将探索使这些组件能够有效协同工作的通信协议。